---
title: "CASYS :: Slalom"
date: 2021-07-05 21:18:00 +0900
categories: Study
tags: 논문
---

# Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware

DNN을 효율적으로 실행하기 위해 linear layer는 TEE가 아닌, 빠르지만 untrusted인 GPU에서 실행함

## 1 Introduction

TEE는 이상적인 untrusted HW보다 성능이 훨씬 안 좋은 것이 문제이다.

ML security에서 TEE 성능 좋게하는 것이 목표 + Trusted Computing Base를 최소화하기 위해 어떻게 trusted/untrusted components에 ML computation을 나눠줄 것인지 고민임



- DNN의 대부분은 linear functions이므로, 이것들을 빠르고 integrity를 보장하며 faster, untrusted GPU에서 돌림

## 어떻게 일부를 untrusted에서 실행하는데 secure인가?
### integrity 
matrix multiplication의 **integrity**를 높은 정확도로 검증하는 방법 : Freivalds
![Lemma2.1]](https://imgur.com/Fto8y6k.png)
#### Freivalds’ Algorithm for Batches (3.2)
잘 이해 못함
#### Preprocessing (3.2)
![Lemma3.1](https://imgur.com/yWeufS9.png)
- 여러 개의 random values s를 여러 layer 및 여러 input에 중복적으로 사용해도 괜찮다.
- DNN weight W는 inference time에 고정되기 때문에, 미리 Ws를 계산해둘 수 있다. 

### privacy
**Privacy**를 위해, GPU에 보내기 전에 random data r을 더한 뒤, f(r)도 구해둔다.
input data x를 Enc(x) = x + r로 암호화한뒤, Enc(x)를 GPU에 보낸다.
GPU는 f(Enc(x)) = f(x+r)을 계산해서 enclave에 다시 보내주는데, f는 linear function이기 때문에 f(x+r) = f(x) + f(r)이고, f(r)은 앞에서 구해놓았기 때문에 enclave는 f(x)를 알 수 있다.
#### 3.3
P1 : Pseudo Random Number Generator (PRNG)를 이용해 blinding factor를 만들고, offline phase에 미리 계산해둔 unblinding factors f(r)를 이용해 online phase에 decrypt함. offline/online phase에 같은 PRNG를 이용해서 blinding factor를 만들기 때문에, 미리 계산해둔 unblinding factors를 사용할 수 있음

P2 : overheads
- untrusted device의 계산은 double-precision을 요구함
- trusted/untrusted간에 데이터 교환이 처음과 끝에만 발생하는게 아니고, layer마다 발생함
- TEE는 미리 계산해둔 unblinding factors를 빠르게 load해와야하므로, RAM이 크거나 disk 접근이 빨라야 함





![eval](https://imgur.com/3wyINW1.png)

Slalom (TEE, GPU)를 써서 단순히 TEE만 쓰는 baseline보다 성능이 좋아지기는 하지만,
security 신경 쓰지 않고 모두 GPU에서 돌리는 것보다는 훨씬 느리다. 
Slalom은 GPU utilization이 작기 때문에, 여러 CPU enclave가 동시에 같은 GPU에 outsource하면 GPU를 더 잘 활용할 수 있다.














