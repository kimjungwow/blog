---
title: "Research :: Osv"
date: 2020-09-17 18:22:00 +0900
categories: Study
tags: Study OS 논문
---

# OSv—Optimizing the Operating System for Virtual Machines 

## 1 Introduction

Cloud computing은 virtualization을 통해 여러 조직이 하나의 machine을 공유하기 좋아서 발달함.

기존에는 physical machine에서 사용되는 Linux, Windows, BSD 등의 OS가 VM에서 사용되었지만, 이러한 OS들이 physical machine에서 사용된 이유 (한 개의 machine을 관리하기 적절 + 다양한 HW 지원)는 VM에서는 의미가 적어졌다. 또한, VM이 빠르고 작고 관리하기 쉬워야 한다는 것이 중요해졌다. 



기존 OS의 기능이 cloud 내 여러 layer에서 중복되어 있어서 overhead가 되었다.

**duplicate 1 : isolate processes**
예를 들면 프로세스 사이의 isolation을 OS가 기존에 신경썼지만, VM에서는 hypervisor가 서로 다른 VM 사이의 isolation을 신경쓴다. 주로 하나의 VM에서 하나의 app을 실행하여 isolation을 잘해서, (기존 OS의 process isolation이 VM에서 쓸 OS는 필요가 없다.)

**duplicate 2 : HW abstraction**
기존의 OS는 app이 HW를 사용할 때 HW abstraction을 제공하지만, VM에서는 hypervisor에 의해 추상화된 HW를 app이 사용한다. 이 duplication도 성능에 영향 미친다.

**Physical machine이 아닌 VM에서 사용할 목적으로 OS를 만들면 어떨까? -> OSv**

OSv의 목표
1. Run existing cloud applications (Linux executables)
1. Run these applications faster than Linux does.
1. Make the image small enough, and the boot quick enough, that staring a new VM becomes a viable alternative to reconfiguring a running one.
1. Explore new APIs for new applications written for OSv, that provide even better performance.
1. Explore using such new APIs in common runtime environments, such as the Java Virtual Machine(JVM). This will boost the performance of unmodified Java applications running on OSv.
1. Be a platform for continued research on VM operating systems. OSv is actively developed as open source, it is written in a modern language (C++11), its codebase is relatively small, and our community encourages experimentation and innovation.

OSv는 architecture-specific code를 최소화하며 다양한 hypervisor와 processors를 지원한다.

## 2 Design and Implementation of OSv

OSv 디자인은 exokernel과 비슷하다. Hypervisor가 exokernel, VM이 application 역할과 비슷하다. 

OSv에서는 VM당 하나의 application을 가정 -> OSv 구성이 단순해지고, VM 내부에서의 isolation은 필요 없다. Hypervisor만 isolation 신경쓰면 된다.  
OSv는 **하나의 address space**를 사용한다. 커널과 모든 thread가 같은 page table을 쓰고, context switching (app thread 사이 혹은 app thread <-> kernel thread) 비용이 적어진다.

OSv의 `ELF dynamic linker` : 리눅스 ABI의 함수를 사용하면 이 linker가 OSv kernel내의 함수를 호출한다. 이 때, `read()` 등 system call도 OSv는 single-application OS이기 때문에 user-to-kernel overhead를 없앨 수 있으므로, system call이 아닌 function call처럼 동작한다.

기존의 app도 OSv에서 잘 동작하기 위해 Linux를 많이 모방했지만, single-app OS에서 필요 없는 `fork(), exec()`은 구현하지 않았다.

OSv는 다양한 HW를 지원하는 physical machine에서의 OS가 아니다. Hypervisor가 더욱 단순한 HW abstraction을 제공하기 때문에, OSv는 자주 사용되는 키보드 등의 장치들을 위한 driver만을 가진다.

### 2.1 Memory Management

libOS는 flat memory 사용하지만, OSv는 일반 OS처럼 virtual memory 사용하는데, 그 이유는
1. x86_64 아키텍쳐가 long mode(64-bit) operation을 사용해서
1. 최근 app들이 map/unmap + 스스로 page protection을 사용해서

OSv는 `mmap` 사용.  
mapping이 크면 OSv는 2MB처럼 큰 사이즈의 페이지 사용 -> TLB miss 적어져 성능 개선  
페이지의 일부만 unmap 돼야 하는 경우, 페이지를 더 작은 크기의 페이지로 나누는 기능 구현  
single-app OS여서 page-evict X

### 2.2 No Spinlocks

Single processor OS에서는 interrupt, context switch를 끄는 것으로 충분하지만, physical machine의 Multi processor OS에서는 여러 CPU가 동시에 같은 데이터를 접근할 수 있어서 spinlock을 얻은 뒤에만 수정가능하게 했다.  
계속 동작하는 Physical CPU와 달리, Virtual CPU는 중간에 멈추기도 한다. (hypervisor에 하거나, hypervisor가 다른 guest 실행하는 등의 이유로.) 이 때 lock을 쥔 상태로 CPU가 멈추면, spinlock을 사용하는 경우 그 lock을 쥐고자하는 다른 CPU는 (sleep하지 않고) spin하며 기다리기 때문에 성능이 저하된다.  
이를 lock-holder preemption problem이라 하는데, OSv는 아예 spin-lock을 사용하지 않음으로써 이를 해결한다. 하지만 그렇다고 일부 기능을 포기하거나 single-processor로 제한되지 않는다.  

OSv에서는
1. 대부분 커널에서의 작업이 thread에서 이루어지며, sleep 가능한 Mutex (Spin-lock X)를 이용한다. 이를 위해 thread context switch의 비용이 적어야 한다.
1. 이 때 Mutex는 lock-free algorithm으로 구현한다.
1. scheduler는 thread에서 동작할 수 없으므로, per-cpu run queues(대부분의 작업이 local to CPU여서 locking이 필요 없음)와 lock-free algorithm(다른 cpu의 thread를 깨우는 경우)을 사용한다.

lock-free algorithm으로 mutex를 구현하려면 `compare-exchange, fetch-and-add`같은 atomic operation을 이용한다.

### 2.3 Network Channels

cloud에서 사용될 OS는 TCP/IP stack이 좋아야 한다.  
networking stack은 top-down (Application thread)와 bottom-up(IRQ context)로 traversed되는데, 이 때 양 방향에서 shared data structure에 접근한다.  
따라서 OSv에서는 대부분의 작업을 application에서 진행함으로써 여러 개의 thread가 shared data structure에 동시에 접근할 일이 없게 한다. 패킷이 도착하면 application thread에 전달하는 channel을 만드는 방식이다.  
이처럼 application thread 한 개만 data에 접근하므로, receive용과 send용 socket buffer lock을 하나로 합칠 수 있다. 또한 interleave lock은 wait queue로 대체하고, TCP layer는 바로 위 socket layer와 함께 동작하므로 TCP layer의 lock을 없앨 수 있다.

### 2.4 The Thread Scheduler

OSv scheduler의 목표는 **lock-free, preemptive, tick-less, fair, scalable, and efficient**이다.

#### Lock-free

OSv scheduler는 CPU마다 runnable threads를 모아둔 run queue를 가진다. 각 CPU마다 queue 있어서 locking 필요 없다. running thread가 reschedule 요청하거나, timer expiration으로 preemption이 요구될 때 scheduler가 CPU에서 동작한다.  
서로 다른 CPU의 run queue에 thread 수가 다를 경우, load balancer가 많은 쪽의 thread 하나를 다른 (remote) CPU에서 wake up하는 식으로 균형을 맞춘다.  
`N`개의 CPU 각각에 총 `N`개의 lock-free queues of *incoming wakeups* 가진다. CPU s가 CPU d에서 thread wakeup 시키고 싶은 경우, queue (s,d)에 넣고 (CPU d의 것인듯), CPU d의 bitmask를 설정한 뒤, CPU d에게 inter-processor interrupt (IPI)를 보낸다. IPI로 인해 CPU d는 reschedule을 수행하는데, 이 때 incoming wakeups를 먼저 확인한다. bitmask를 통해 s의 thread가 있는 incoming queue를 확인할 수 있다.

#### Preemptive

kernel thread, application threads 모두 (wait, yield, wake up으로 ) reschedule 될 수도 있고 timer나 wakeup IPI로 preempted 될 수도 있다. per-thread preempt-disable counter를 늘림으로써 일시적으로 preemtped 되지 않을 수 있는데, 이는 per-CPU variables나 RCU lock을 유지할 떄 유용하다.

#### Tick-less

통상 kernel은 정기적으로 timer interrupt (tick)을 발생시켜 reschedule한다. 각 thread별로 실행한 시간 (ticks)를 계산하여, 어떤 thread를 schedule할지 정하기도 한다.  
하지만 과도한 tick(timer interrupt)은 CPU time을 낭비한다. VM에서는 timer interrupt가 exit to hypervisor도 포함해 더 오래 걸려서, CPU time이 더 많이 낭비된다.  
따라서 OSv는 tick-less 디자인을 선택했는데, high resolution clock을 이용함으로써 thread의 정확한 실행 시간을 계산한다. (ticks로 어림잡지 않음) thread를 실행할 때 언제 다음 thread로 switch할지를 기억할 때는 timer interrupt가 사용되며, 비슷한 priority의 두 thread가 있는 경우 너무 자주 switch 되지 않도록 한다. (hysteresis 이력 현상)